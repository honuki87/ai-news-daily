"""
ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ AI ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ëª¨ë“ˆ
"""
import os
import urllib.request
import urllib.parse
import json
import re
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

def clean_html(text: str) -> str:
    """HTML íƒœê·¸ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°"""
    text = re.sub(r'<[^>]+>', '', text)
    text = text.replace('&quot;', '"').replace('&amp;', '&')
    text = text.replace('&lt;', '<').replace('&gt;', '>')
    text = text.replace('&apos;', "'")
    return text.strip()


def get_ai_news(query: str = "AI ì¸ê³µì§€ëŠ¥", display: int = 10) -> list[dict]:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¡œ AI ê´€ë ¨ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    
    Args:
        query: ê²€ìƒ‰ì–´
        display: ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜ (ìµœëŒ€ 100)
    
    Returns:
        ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ [{title, link, description, pubDate}, ...]
    """
    encoded_query = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/news.json?query={encoded_query}&display={display}&sort=sim"
    
    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
    request.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
    
    try:
        response = urllib.request.urlopen(request)
        if response.getcode() == 200:
            data = json.loads(response.read().decode('utf-8'))
            items = data.get('items', [])
            
            news_list = []
            for item in items:
                news_list.append({
                    'title': clean_html(item.get('title', '')),
                    'link': item.get('link', ''),
                    'description': clean_html(item.get('description', '')),
                    'pubDate': item.get('pubDate', '')
                })
            
            return news_list
    except Exception as e:
        print(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return []


def extract_keywords(title: str) -> set:
    """ì œëª©ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ì¤‘ë³µ ë¹„êµìš©)"""
    # ë¶ˆìš©ì–´ ì œê±°
    stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 
                 'ì˜', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ì„', 'ë¥¼', 'ì—', 'ì™€', 'ê³¼', 
                 'ë¡œ', 'ìœ¼ë¡œ', 'ì—ì„œ', 'ë„', 'ë§Œ', 'ê¹Œì§€', 'ë¶€í„°', 'ì—ê²Œ'}
    
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
    clean_title = re.sub(r'[^\w\s]', ' ', title.lower())
    words = clean_title.split()
    
    # ë¶ˆìš©ì–´ ì œê±° ë° 2ê¸€ì ì´ìƒë§Œ
    keywords = {w for w in words if w not in stopwords and len(w) >= 2}
    return keywords


def is_similar_title(title1: str, title2: str, threshold: float = 0.25) -> bool:
    """ë‘ ì œëª©ì˜ ìœ ì‚¬ë„ ë¹„êµ (í‚¤ì›Œë“œ ê¸°ë°˜)"""
    keywords1 = extract_keywords(title1)
    keywords2 = extract_keywords(title2)
    
    if not keywords1 or not keywords2:
        return False
    
    # í•µì‹¬ ì—”í‹°í‹° (íšŒì‚¬ëª…, ì œí’ˆëª…) - ì´ í‚¤ì›Œë“œê°€ 2ê°œ ì´ìƒ ê²¹ì¹˜ë©´ ê°™ì€ ë‰´ìŠ¤ë¡œ íŒë‹¨
    key_entities = {'ì• í”Œ', 'apple', 'êµ¬ê¸€', 'google', 'ì‚¼ì„±', 'samsung', 'sk', 'lg', 
                    'ë„¤ì´ë²„', 'naver', 'ì¹´ì¹´ì˜¤', 'kakao', 'ë§ˆì´í¬ë¡œì†Œí”„íŠ¸', 'microsoft', 
                    'openai', 'chatgpt', 'ì œë¯¸ë‚˜ì´', 'gemini', 'í´ë¡œë“œ', 'claude',
                    'í•˜ì´ë‹‰ìŠ¤', 'ì—”ë¹„ë””ì•„', 'nvidia', 'í…ŒìŠ¬ë¼', 'tesla', 'ë©”íƒ€', 'meta',
                    'ì‹œì´', 'íˆ¬ì', 'ë‹¬ëŸ¬', 'ì¡°ì›'}
    
    # í•µì‹¬ ì—”í‹°í‹° ê²¹ì¹¨ ì²´í¬
    common_keywords = keywords1 & keywords2
    common_entities = common_keywords & key_entities
    
    # í•µì‹¬ ì—”í‹°í‹°ê°€ 2ê°œ ì´ìƒ ê²¹ì¹˜ë©´ ê°™ì€ ë‰´ìŠ¤ë¡œ íŒë‹¨
    if len(common_entities) >= 2:
        return True
    
    # Jaccard ìœ ì‚¬ë„ ê³„ì‚°
    intersection = len(common_keywords)
    union = len(keywords1 | keywords2)
    
    similarity = intersection / union if union > 0 else 0
    return similarity >= threshold


def get_top_ai_news(count: int = 5) -> list[dict]:
    """
    AI ê´€ë ¨ TOP ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ì¤‘ë³µ ì œê±° í¬í•¨)
    
    Args:
        count: ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜
    
    Returns:
        ìƒìœ„ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
    """
    # ì—¬ëŸ¬ ê²€ìƒ‰ì–´ë¡œ ë‰´ìŠ¤ ìˆ˜ì§‘
    queries = ["AI ì¸ê³µì§€ëŠ¥", "ChatGPT", "ìƒì„±í˜•AI", "LLM", "ë¨¸ì‹ ëŸ¬ë‹"]
    all_news = []
    seen_links = set()
    
    for query in queries:
        news = get_ai_news(query, display=15)  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ ì¤‘ë³µ ì œê±° í›„ ì„ ë³„
        for item in news:
            if item['link'] not in seen_links:
                # ì œëª© ìœ ì‚¬ë„ ì²´í¬ - ê¸°ì¡´ ë‰´ìŠ¤ì™€ ë„ˆë¬´ ë¹„ìŠ·í•˜ë©´ ìŠ¤í‚µ
                is_duplicate = False
                for existing in all_news:
                    if is_similar_title(item['title'], existing['title']):
                        is_duplicate = True
                        break
                
                if not is_duplicate:
                    seen_links.add(item['link'])
                    all_news.append(item)
    
    # ìƒìœ„ Nê°œ ë°˜í™˜
    return all_news[:count]


def format_news_for_kakao(news_list: list[dict]) -> str:
    """ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ìš©ìœ¼ë¡œ ë‰´ìŠ¤ í¬ë§·íŒ…"""
    today = datetime.now().strftime("%Yë…„ %mì›” %dì¼")
    
    message = f"ğŸ¤– ì˜¤ëŠ˜ì˜ AI ë‰´ìŠ¤ ({today})\n\n"
    
    for i, news in enumerate(news_list, 1):
        title = news['title'][:50] + "..." if len(news['title']) > 50 else news['title']
        message += f"{i}. {title}\n"
        message += f"   ğŸ‘‰ {news['link']}\n\n"
    
    return message


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    news = get_top_ai_news(5)
    print(format_news_for_kakao(news))
